{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy\n",
    "\n",
    "#importing prophet\n",
    "from fbprophet import Prophet\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from fbprophet import Prophet\n",
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from pandas import ExcelWriter\n",
    "from pandas import ExcelFile\n",
    "import numpy as np\n",
    "from fbprophet.diagnostics import cross_validation\n",
    "from fbprophet.diagnostics import performance_metrics\n",
    "from fbprophet.plot import add_changepoints_to_plot\n",
    "\n",
    "#Visualizing Interactive Plots\n",
    "from plotly.offline import init_notebook_mode, iplot\n",
    "from plotly import graph_objs as go\n",
    "from datetime import datetime\n",
    "\n",
    "from datetime import timedelta, date\n",
    "\n",
    "start_date = date(2017, 1, 3)\n",
    "today_date = datetime.today().strftime('%Y-%m-%d')\n",
    "end_date = date(2020, 1, 1)\n",
    "dataframeall = pd.DataFrame()\n",
    "dataframeall = pd.concat([pd.DataFrame({'Date': pd.date_range(start_date, end_date, freq='d')}, columns=['Date'])])\n",
    "dataframeall = dataframeall[:-1]\n",
    "\n",
    "\n",
    "# Initialize plotly\n",
    "init_notebook_mode(connected=True)\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "#weekend\n",
    "def weekend(ds):\n",
    "    date = pd.to_datetime(ds)\n",
    "    if date.weekday() == 5 or date.weekday() == 6:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "#usHolidays\n",
    "usHolidays = pd.DataFrame({\n",
    "  'holiday': 'usHolidays',\n",
    "  'ds': pd.to_datetime(['2016-01-18', '2016-02-15', '2016-05-30', '2016-07-04',\n",
    "               '2016-09-05', '2016-10-10', '2016-11-11', '2016-11-24',\n",
    "               '2016-12-26', '2017-01-02', '2017-01-16', '2017-02-20',\n",
    "               '2017-05-29', '2017-07-04', '2017-09-04', '2017-10-09',\n",
    "               '2017-11-10', '2017-11-23', '2017-12-25', '2018-01-01',\n",
    "               '2018-01-15', '2018-02-19', '2018-05-28', '2018-07-04',\n",
    "               '2018-09-03', '2018-10-08', '2018-11-12', '2018-11-22',\n",
    "               '2018-12-25', '2019-01-01', '2019-01-21', '2019-02-18',\n",
    "               '2019-05-27', '2019-07-04', '2019-09-02', '2019-10-14',\n",
    "               '2019-11-11', '2019-11-28', '2019-12-25','2019-12-31']),\n",
    "  'lower_window': 0,\n",
    "  'upper_window': 1,\n",
    "})\n",
    "holidays =usHolidays\n",
    "holidays\n",
    "\n",
    "#plotly_df\n",
    "def plotly_df(df, title=''):\n",
    "    \"\"\"Visualize all the dataframe columns as line plots.\"\"\"\n",
    "    common_kw = dict(x=df.index, mode='lines')\n",
    "    data = [go.Scatter(y=df[c], name=c, **common_kw) for c in df.columns]\n",
    "    layout = dict(title=title)\n",
    "    fig = dict(data=data, layout=layout)\n",
    "    iplot(fig, show_link=False)\n",
    "\n",
    "\n",
    "# Load dataset\n",
    "cust_orders = pd.read_csv(\"5l_customer_orders_127.csv\", index_col= 'Group')\n",
    "#fill with 0\n",
    "cust_orders_head=cust_orders.fillna(0)\n",
    "#create dataframe\n",
    "df = pd.DataFrame(cust_orders_head)\n",
    "\n",
    "df['Date'] =pd.to_datetime(df.Date)\n",
    "df = df.sort_values('Date')\n",
    "\n",
    "today_date = datetime.today().strftime('%Y-%m-%d')\n",
    "mask = (df['Date'] < today_date)\n",
    "df_mask = df.loc[mask]\n",
    "\n",
    "\n",
    "df_wo_wknd_re = df_mask\n",
    "#print('df_wo_wknd_re ',df_wo_wknd_re)\n",
    "df_wo_wknd_re = df_wo_wknd_re.reset_index()\n",
    "\n",
    "df_wo_wknd_re = df_wo_wknd_re.set_index('Date')\n",
    "\n",
    "\n",
    "# for testing data\n",
    "#print(df_mask)\n",
    "df_mask['weekend'] = df_mask['Date'].apply(weekend)\n",
    "df_mask['weekend']\n",
    "df_wo_wknd = df_mask[df_mask.weekend != 1]\n",
    "df_wo_wknd_re_test = df_wo_wknd\n",
    "df_wo_wknd_re_test = df_wo_wknd_re_test.reset_index()\n",
    "\n",
    "df_wo_wknd_re_test = df_wo_wknd_re_test.set_index('Date')\n",
    "\n",
    "group_code_unique = df_wo_wknd_re['Group'].unique()\n",
    "\n",
    "\n",
    "start_date = today_date\n",
    "end_date = date(2019, 12, 31)\n",
    "test_df_all = pd.DataFrame()\n",
    "test_df_all = pd.concat([pd.DataFrame({'Date': pd.date_range(start_date, end_date, freq='d')}, columns=['Date'])])\n",
    "test_df_all\n",
    "\n",
    "master_index=0\n",
    "#for each master/group code, genrate loop\n",
    "for master in group_code_unique:\n",
    "    print(master)\n",
    "    df_wo_wknd_ele = df_wo_wknd_re.loc[df_wo_wknd_re['Group'] == master]\n",
    "\n",
    "    df_wo_wknd_ele = df_wo_wknd_ele.reset_index()\n",
    "\n",
    "    df_wo_wknd_ele = df_wo_wknd_ele.drop(['Group'],axis=1)\n",
    "    df_wo_wknd_ele_tr = df_wo_wknd_ele.transpose()\n",
    "    \n",
    "    grouped = df_wo_wknd_ele.groupby(['Date'])['Quantity'].apply(np.sum)\n",
    "    \n",
    "    grouped_df =pd.DataFrame(grouped,columns= [ 'Quantity'])\n",
    "    grouped_df.columns =[master]\n",
    "    \n",
    "    \n",
    "    #for test data\n",
    "    \n",
    "    df_wo_wknd_ele_test = df_wo_wknd_re_test.loc[df_wo_wknd_re_test['Group'] == master]\n",
    "\n",
    "    df_wo_wknd_ele_test = df_wo_wknd_ele_test.reset_index()\n",
    "\n",
    "    df_wo_wknd_ele_test = df_wo_wknd_ele_test.drop(['Group'],axis=1)\n",
    "    #df_wo_wknd_ele_tr = df_wo_wknd_ele.transpose()\n",
    "    \n",
    "    grouped_test = df_wo_wknd_ele_test.groupby(['Date'])['Quantity'].apply(np.sum)\n",
    "    \n",
    "    grouped_df_test =pd.DataFrame(grouped_test,columns= [ 'Quantity'])\n",
    "    grouped_df_test.columns =[master]\n",
    "    \n",
    "    # Splitting Train test data for individual Master codes\n",
    "    train_size = int(len(grouped_df))\n",
    "    #test_size = int(len(test_df_all))\n",
    "    train = grouped_df[:train_size]\n",
    "    #test = test_df_all\n",
    "    train['Date'] = train.index\n",
    "    train['Date'] = train['Date'].astype('datetime64[ns]')\n",
    "    train = train.set_index('Date')\n",
    "    #test['Date'] = test.index\n",
    "    #test['Date'] = test['Date'].astype('datetime64[ns]')\n",
    "    #test = test.set_index('Date')\n",
    "    #test_transposed = test.transpose()\n",
    "    #test['ds'] = test.index\n",
    "    #test['ds'] = test['ds'].astype('datetime64[ns]')\n",
    "    train_transposed = train.transpose()\n",
    "    #test_transposed = test.transpose()\n",
    "    # Prediction size\n",
    "    prediction_size = int(len(test_df_all))\n",
    "    new = pd.DataFrame(train_transposed.iloc[0])\n",
    "    #ax = plt.gca()\n",
    "    \n",
    "    # create 'ds' and 'y' elements for Prophet ML algo\n",
    "    new['ds'] = train_transposed.columns\n",
    "    new['ds'] = new['ds'].astype('datetime64[ns]')\n",
    "    new.columns = ['y', 'ds']\n",
    "    new_table = new[['ds','y']]\n",
    "    new_table.set_index('ds')\n",
    "    \n",
    "    #create Model by calling Prophet\n",
    "    my_model = Prophet(interval_width=0.95, holidays=holidays)\n",
    "    \n",
    "    #Add Daily Seasonality\n",
    "    my_model.add_seasonality(name='daily', period=1, fourier_order=4)\n",
    "    \n",
    "    #Plot Graph with existing data\n",
    "    #plotly_df(new,'Daily Shipment Seasonality')\n",
    "    \n",
    "    # Fit model on train data\n",
    "    my_model.fit(new_table)\n",
    "    # Make Future Dataframe with daily frequency and Prediction size\n",
    "    future_dates = my_model.make_future_dataframe(periods = prediction_size, freq =\"d\")\n",
    "    temp_history_dates = future_dates[future_dates['ds']<today_date]\n",
    "    temp_future_dates = future_dates[future_dates['ds']>=today_date]\n",
    "    temp_future_dates['weekend'] = temp_future_dates['ds'].apply(weekend)\n",
    "    temp_future_dates = temp_future_dates[temp_future_dates.weekend != 1]\n",
    "    \n",
    "    temp_future_dates = temp_future_dates.drop(['weekend'], axis=1)\n",
    "    future_dates = pd.merge(temp_history_dates, temp_future_dates, on=['ds'] , how='outer')\n",
    "    future_dates = future_dates.reset_index()\n",
    "    \n",
    "    forecast = my_model.predict(future_dates)\n",
    "    forecast = round(forecast)\n",
    "    \n",
    "    #Plot Forecast\n",
    "    #figure = my_model.plot(forecast)\n",
    "    #for changepoint in my_model.changepoints:\n",
    "    #    plt.axvline(changepoint,ls='--', lw=1)\n",
    "\n",
    "    # Merge forecasts with given IDs for Model 1\n",
    "    #test_merge = pd.merge(forecast, test, on=['ds'] , how='outer')\n",
    "    #cols = ['ds','yhat']\n",
    "    #test_new = test_merge[cols]\n",
    "    cols = ['ds','yhat']\n",
    "    test_new = forecast[cols]\n",
    "    test_new.yhat[test_new.yhat < 0] = 0\n",
    "\n",
    "    # Forecasted data\n",
    "    fc = test_new[['ds', 'yhat']].copy()\n",
    "    fc[master] = fc['yhat']\n",
    "    fc =  fc.drop('yhat', axis=1)\n",
    "    fc['ds'] = fc['ds'].astype('datetime64[ns]')\n",
    "\n",
    "    fc_transposed = fc.transpose()\n",
    "    fc_transposed.columns = fc.index.values\n",
    "    \n",
    "    print('length::: ',len(grouped_df ))\n",
    "    \n",
    "    test_val = fc[fc['ds'] >= today_date]\n",
    "    #print('test_val ',test_val)\n",
    "    #fc_re['weekend'] = fc_re['ds'+master].apply(weekend)\n",
    "    #fc_re = fc_re[fc_re.weekend != 1]\n",
    "    grouped_df = grouped_df.reset_index()\n",
    "    grouped_df_transposed = grouped_df.transpose()\n",
    "    if master_index == 0:\n",
    "        idx = 0\n",
    "        columns = train.columns\n",
    "        fc_re = pd.DataFrame(columns=columns)\n",
    "        grouped_df_transposed_re = pd.DataFrame(columns=columns)\n",
    "        #new_col = fc_transposed.iloc[master_index] #be a list, a Series, an array or a scalar \n",
    "        new_col = pd.Series()\n",
    "        new_col = pd.to_datetime(pd.Series(dataframeall['Date'])) #be a list, a Series, an array or a scalar \n",
    "        fc_re.insert(loc=idx, column='dates', value=new_col)\n",
    "        fc_re['ds'+master] = fc_transposed.iloc[master_index].astype('datetime64[ns]')\n",
    "        \n",
    "        #grouped_df_transposed_re\n",
    "        grouped_df_transposed_re.insert(loc=idx, column='dates', value=new_col)\n",
    "        grouped_df_transposed_re['ds'+master] = grouped_df_transposed.iloc[master_index].astype('datetime64[ns]')\n",
    "    else:\n",
    "        fc_re['ds'+master] = fc['ds']\n",
    "        grouped_df_transposed_re['ds'+master] = grouped_df['Date']\n",
    "    \n",
    "    #test_merge = pd.merge(forecast, test, on=['ds'] , how='outer')\n",
    "    fc_re[master] = fc[master]\n",
    "    grouped_df_transposed_re[master] = grouped_df[master]\n",
    "    \n",
    "    #print(fc_re[master])\n",
    "\n",
    "    #fc_re[master] = fc_re[master].fillna(0)\n",
    "    #fc_re['weekend'+master] = fc_re['ds'+master].apply(weekend)\n",
    "    #fc_re = fc_re[fc_re['weekend'+master] != 1]\n",
    "\n",
    "    test_new = round(test_new)\n",
    "    test_new_df = test_new[['ds', 'yhat']].copy()\n",
    "    test_new_df['y']=test_new['yhat'] #copy the log-transformed data to another column\n",
    "    \n",
    "    master_index+=1\n",
    "print('Forecasting done')\n",
    "#print('fc_re ', fc_re)\n",
    "print('-------------grouped_df_transposed_re--------------------')\n",
    "print(grouped_df_transposed_re)\n",
    "\n",
    "#to add later on\n",
    "#fc_re['weekend'] = fc_re['ds'].apply(weekend)\n",
    "#fc_re\n",
    "#fc_re = fc_re[fc_re.weekend != 1]\n",
    "#fc_re\n",
    "#fc_re\n",
    "\n",
    "from datetime import timedelta, date\n",
    "import pandas as pd\n",
    "#date(2019, 12, 31)\n",
    "start_date = date(2017, 1, 3)\n",
    "end_date = today_date\n",
    "histdates = pd.DataFrame()\n",
    "histdates = pd.concat([pd.DataFrame({'Date': pd.date_range(start_date, end_date, freq='d')}, columns=['Date'])])\n",
    "histdates\n",
    "\n",
    "histdates = histdates[:-1]\n",
    "histdates\n",
    "\n",
    "# removing weekend from future dates - test_df_all\n",
    "test_df_all['weekend'] = test_df_all['Date'].apply(weekend)\n",
    "test_df_all = test_df_all[test_df_all.weekend != 1]\n",
    "test_df_all\n",
    "test_df_all = test_df_all.drop(['weekend'],axis=1)\n",
    "test_df_all\n",
    "test_df_all.index = range(0,len(test_df_all ))\n",
    "test_df_all\n",
    "\n",
    "# Merge forecasts with given IDs for Model 1\n",
    "merge_all = pd.merge(histdates, test_df_all, on=['Date'] , how='outer')\n",
    "#cols = ['ds','yhat']\n",
    "#test_new = test_merge[cols]\n",
    "merge_all['Date']\n",
    "\n",
    "import numpy\n",
    "\n",
    "dates = pd.to_datetime(pd.Series(merge_all['Date']), format = '%Y%m%d')\n",
    "dates = dates.apply(lambda x: x.strftime('%Y-%m-%d'))\n",
    "#print(len(group_code_unique))\n",
    "new_re = pd.DataFrame()\n",
    "new_re['Date'] = merge_all['Date']\n",
    "for k in range(len(group_code_unique)):\n",
    "    fc_redates = pd.to_datetime(pd.Series(fc_re['ds'+group_code_unique[k]][fc_re['ds'+group_code_unique[k]].notnull()]))\n",
    "    fc_redates = fc_redates.apply(lambda x: x.strftime('%Y-%m-%d'))\n",
    "    i=0\n",
    "    new_df_fc_redates = pd.DataFrame(columns =['Date',group_code_unique[k]])\n",
    "    for single in dates:\n",
    "        vals = fc_redates[fc_redates.astype(str).str.contains(single)]\n",
    "        if (len(vals) == 1):\n",
    "            vals =  pd.to_datetime(vals.values)\n",
    "            value = fc_re.loc[i,group_code_unique[k]]\n",
    "            new_df_fc_redates = new_df_fc_redates.append({'Date':vals.values, group_code_unique[k]:value}, ignore_index=True)\n",
    "        else:\n",
    "            i=i-1\n",
    "            vals =  pd.to_datetime(vals.values)\n",
    "            new_df_fc_redates = new_df_fc_redates.append({'Date':vals.values, group_code_unique[k]:0}, ignore_index=True)\n",
    "        i+=1\n",
    "    new_re[group_code_unique[k]] = new_df_fc_redates[group_code_unique[k]]\n",
    "new_df_fc_redates\n",
    "\n",
    "new_re['ds'] = new_re['Date']\n",
    "new_re\n",
    "\n",
    "#grouped_df_transposed_re \n",
    "new_re_grouped = pd.DataFrame()\n",
    "grouped_df_transposed_re = grouped_df_transposed_re.reset_index()\n",
    "print(grouped_df_transposed_re)\n",
    "new_re_grouped['Date'] = histdates['Date']\n",
    "for k in range(len(group_code_unique)):\n",
    "    print(pd.Series(grouped_df_transposed_re['ds'+group_code_unique[k]]))\n",
    "    \n",
    "    grouped_redates = pd.to_datetime(pd.Series(grouped_df_transposed_re['ds'+group_code_unique[k]][grouped_df_transposed_re['ds'+group_code_unique[k]].notnull()]))\n",
    "    grouped_redates = grouped_redates.apply(lambda x: x.strftime('%Y-%m-%d'))\n",
    "    i=0\n",
    "    new_df_grouped_redates = pd.DataFrame(columns =['Date',group_code_unique[k]])\n",
    "    for single in dates:\n",
    "        vals = grouped_redates[grouped_redates.astype(str).str.contains(single)]\n",
    "        if (len(vals) == 1):\n",
    "            vals =  pd.to_datetime(vals.values)\n",
    "            value = grouped_df_transposed_re.loc[i,group_code_unique[k]]\n",
    "            new_df_grouped_redates = new_df_grouped_redates.append({'Date':vals.values, group_code_unique[k]:value}, ignore_index=True)\n",
    "        else:\n",
    "            i=i-1\n",
    "            vals =  pd.to_datetime(vals.values)\n",
    "            new_df_grouped_redates = new_df_grouped_redates.append({'Date':vals.values, group_code_unique[k]:0}, ignore_index=True)\n",
    "        i+=1\n",
    "    new_re_grouped[group_code_unique[k]] = new_df_grouped_redates[group_code_unique[k]]\n",
    "new_df_grouped_redates\n",
    "\n",
    "grouped_df_transposed_re = grouped_df_transposed_re.drop(['index'],axis=1)\n",
    "grouped_df_transposed_re\n",
    "\n",
    "new_re_grouped = new_re_grouped.set_index('Date')\n",
    "new_re_grouped = new_re_grouped.fillna(0)\n",
    "\n",
    "output = new_re.transpose()\n",
    "output.columns = new_re['ds']\n",
    "new_header = output.iloc[0] #grab the first row for the header\n",
    "reoutput = output[1:] #take the data less the header row\n",
    "reoutput.columns = new_header #set the header row as the df header\n",
    "reoutput = reoutput.drop(['ds'],axis = 0)\n",
    "reoutput = reoutput.astype('float64')\n",
    "grouped_df_transposed.columns = pd.to_datetime(grouped_df_transposed.columns)\n",
    "new_values =reoutput.copy()\n",
    "reoutput.update(new_re_grouped.transpose())\n",
    "vals = new_re_grouped.iloc[:,0:]\n",
    "vals.to_dict('series')\n",
    "dataframe = pd.DataFrame(new_values)\n",
    "diff = dataframe.subtract(vals.transpose(), axis = 1)\n",
    "diff =abs(diff)\n",
    "# Absolute Values - sum over the column axis. \n",
    "sum_absolute_vals = diff.sum(axis = 1, skipna = True)\n",
    "sum_absolute_vals\n",
    "diff\n",
    "new_values_trans = new_values.transpose()\n",
    "new_values_trans\n",
    "\n",
    "#Actual Values\n",
    "sum_actual_vals = reoutput.sum(axis = 1, skipna = True)\n",
    "sum_actual_vals\n",
    "\n",
    "#MAPE Calculation\n",
    "mape_error_rate = sum_absolute_vals.div(sum_actual_vals)\n",
    "mape_error_rate\n",
    "\n",
    "\n",
    "reoutput.insert(0, \"Error Rate\", mape_error_rate, True) \n",
    "writer = ExcelWriter('forecast_customer_orders_daily.xlsx')\n",
    "reoutput.to_excel(writer,'Sheet1',index=True)\n",
    "writer.save()\n",
    "\n",
    "\n",
    "reoutput_month = pd.DataFrame()\n",
    "reoutput_month = reoutput.transpose()\n",
    "reoutput_month = reoutput_month.set_index(pd.to_datetime(reoutput.transpose().index))\n",
    "reoutput_month = reoutput_month.resample('1M').sum()\n",
    "reoutput_month\n",
    "\n",
    "import calendar\n",
    "reoutput_month['month'] = pd.to_datetime(reoutput_month.index).month\n",
    "reoutput_month['year'] = pd.to_datetime(reoutput_month.index).year\n",
    "reoutput_month['month'] \n",
    "reoutput_month['month'] = reoutput_month['month'].apply(lambda x: calendar.month_abbr[x])\n",
    "reoutput_month['month'] = reoutput_month['month'].astype(str)\n",
    "reoutput_month['year'] = reoutput_month['year'].astype(str)\n",
    "reoutput_month['Period'] = reoutput_month['month']+ ', ' + reoutput_month['year']\n",
    "reoutput_month['Period']\n",
    "reoutput_month = reoutput_month.reset_index()\n",
    "reoutput_month = reoutput_month.drop(['month','year','Date'], axis=1)\n",
    "reoutput_month = reoutput_month.set_index('Period')\n",
    "reoutput_month\n",
    "\n",
    "writer = ExcelWriter('forecast_customer_orders_monthly.xlsx')\n",
    "reoutput_month.transpose().to_excel(writer,'Sheet1',index=True)\n",
    "writer.save()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
